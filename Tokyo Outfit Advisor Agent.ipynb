{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Capstone Project Writeup\n\n## Track\nConcierge Agents\n\n## Problem & Solution Pitch\n### Problem\n\nPeople often waste time checking the weather and still feel unsure about what to wear - especially in a city like Tokyo, where conditions change quickly.\n\n### Solution\n\nI will build a Tokyo Outfit Advisor Agent that automatically fetches the latest weather forecast and gives simple, clear clothing recommendations based on real-time conditions.\n\n## Agent Purpose\n\nThis agent provides real-time clothing advice for walks in Tokyo based on the latest weather conditions.\nIt uses the Gemini 2.5 Flash-Lite model to interpret user queries, search for current weather information, and generate clear, practical recommendations.\n\n## Features Included (Required 3+, I have 4):\n\n„Éª LLM-powered agent ‚úîÔ∏è\nThe main reasoning and planning steps are performed by a Gemini-based agent.\n\n„Éª Built-in Google Search Tool (Grounded Web Search) ‚úîÔ∏è\nThe agent retrieves live weather information for Tokyo using the integrated search tool.\n\n„Éª Session & Memory Support ‚úîÔ∏è\nThrough InMemorySessionService, the agent remembers earlier messages within the same session, enabling natural follow-up interactions.\n\n„Éª Observability Plugins (Invocation counter + logging) ‚úîÔ∏è\nA custom plugin tracks how many times the agent is invoked. Logging is enabled for visibility during execution.\n\n## How the Agent Works\n\nThe user asks how to dress for a walk in Tokyo.\nThe agent performs a grounded web search to obtain the current weather forecast and then generates clear, concise clothing advice.\nIf the user asks follow-up questions (e.g., what else to bring), the agent uses session memory to recall its previous recommendation and answer consistently.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:56:13.147173Z","iopub.execute_input":"2025-11-24T06:56:13.147595Z","iopub.status.idle":"2025-11-24T06:56:13.589224Z","shell.execute_reply.started":"2025-11-24T06:56:13.147534Z","shell.execute_reply":"2025-11-24T06:56:13.588155Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:56:19.651849Z","iopub.execute_input":"2025-11-24T06:56:19.652176Z","iopub.status.idle":"2025-11-24T06:56:19.769696Z","shell.execute_reply.started":"2025-11-24T06:56:19.652152Z","shell.execute_reply":"2025-11-24T06:56:19.768417Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from google.adk.agents import Agent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import google_search\nfrom google.genai import types\nfrom google.adk.plugins.base_plugin import BasePlugin\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:56:22.477275Z","iopub.execute_input":"2025-11-24T06:56:22.477780Z","iopub.status.idle":"2025-11-24T06:56:50.635950Z","shell.execute_reply.started":"2025-11-24T06:56:22.477752Z","shell.execute_reply":"2025-11-24T06:56:50.634747Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define helper functions that will be reused throughout the notebook\n\nfrom IPython.core.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n# Gets the proxied URL in the Kaggle Notebooks environment\ndef get_adk_proxy_url():\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0]['base_url']\n\n    try:\n        path_parts = baseURL.split('/')\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:57:03.964378Z","iopub.execute_input":"2025-11-24T06:57:03.965013Z","iopub.status.idle":"2025-11-24T06:57:04.163916Z","shell.execute_reply.started":"2025-11-24T06:57:03.964978Z","shell.execute_reply":"2025-11-24T06:57:04.162446Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Helper functions defined.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Observability plugin\nclass CountInvocationPlugin(BasePlugin):\n    \"\"\"Simple observability plugin that logs agent, LLM, and tool calls.\"\"\"\n\n    def __init__(self) -> None:\n        super().__init__(name=\"count_invocation\")\n        self.agent_count = 0\n        self.tool_count = 0\n        self.llm_request_count = 0\n\n    async def before_agent_callback(self, agent, callback_context):\n        \"\"\"Called before each agent run.\"\"\"\n        self.agent_count += 1\n        print(f\"[plugin] Agent runs so far: {self.agent_count}\")\n\n    async def before_model_callback(self, callback_context, llm_request, **kwargs):\n        \"\"\"Called before each LLM request.\"\"\"\n        self.llm_request_count += 1\n        # llm_request is a LlmRequest object; model name is in llm_request.model\n        print(f\"[plugin] LLM request #{self.llm_request_count} (model={llm_request.model})\")\n\n    async def after_tool_callback(self, tool, tool_context, result):\n        \"\"\"Called after each tool invocation.\"\"\"\n        self.tool_count += 1\n        print(f\"[plugin] Tool '{tool.name}' completed. Total tool calls: {self.tool_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:59:30.594465Z","iopub.execute_input":"2025-11-24T06:59:30.594896Z","iopub.status.idle":"2025-11-24T06:59:30.602773Z","shell.execute_reply.started":"2025-11-24T06:59:30.594858Z","shell.execute_reply":"2025-11-24T06:59:30.601189Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"root_agent = Agent(\n    name=\"tokyo_outfit_agent\",\n    model=\"gemini-2.5-flash-lite\",\n    description=\"Agent that checks Tokyo weather and suggests what to wear.\",\n    instruction=(\n        \"You are a helpful assistant based in Tokyo.\\n\"\n        \"Your task is to:\\n\"\n        \"1) Use the google_search tool to check the latest weather forecast for Tokyo.\\n\"\n        \"2) Based on the forecast, recommend what the user should wear (layers, jacket, \"\n        \"umbrella, shoes, etc.).\\n\"\n        \"3) Always answer in clear English.\\n\"\n        \"4) Never hallucinate weather data; if search fails, say so explicitly.\"\n    ),\n    tools=[google_search],\n)\n\nprint(\"‚úÖ Root Agent defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T07:02:37.079243Z","iopub.execute_input":"2025-11-24T07:02:37.079608Z","iopub.status.idle":"2025-11-24T07:02:37.086165Z","shell.execute_reply.started":"2025-11-24T07:02:37.079581Z","shell.execute_reply":"2025-11-24T07:02:37.085145Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Root Agent defined.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Runner with plugin for observability\nrunner = InMemoryRunner(\n    agent=root_agent,\n    app_name=\"tokyo_weather_outfit_app\",\n    plugins=[CountInvocationPlugin()],\n)\n\nprint(\"‚úÖ Runner created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T07:02:39.440319Z","iopub.execute_input":"2025-11-24T07:02:39.440779Z","iopub.status.idle":"2025-11-24T07:02:39.447879Z","shell.execute_reply.started":"2025-11-24T07:02:39.440744Z","shell.execute_reply":"2025-11-24T07:02:39.446875Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Runner created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def pretty_print(event):\n    \"\"\"Safely extract and print only the human-readable text from an Event.\"\"\"\n    try:\n        content = getattr(event, \"content\", None)\n        if not content:\n            print(event)\n            return\n\n        parts = getattr(content, \"parts\", [])\n        texts = []\n        for part in parts:\n            text = getattr(part, \"text\", None)\n            if text:\n                texts.append(text)\n\n        if texts:\n            print(\"\\n\".join(texts))\n        else:\n            print(\"(no text content)\")\n    except Exception as e:\n        print(f\"Error while printing event: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T07:10:01.310799Z","iopub.execute_input":"2025-11-24T07:10:01.311176Z","iopub.status.idle":"2025-11-24T07:10:01.318746Z","shell.execute_reply.started":"2025-11-24T07:10:01.311145Z","shell.execute_reply":"2025-11-24T07:10:01.317205Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import pprint\n\nasync def run_session_example() -> None:\n    # Create a session so that the agent can keep context between turns\n    session = await runner.session_service.create_session(\n        app_name=runner.app_name,\n        user_id=\"demo_user\",\n    )\n\n    print(\"=== Turn 1: initial question ===\")\n    first_prompt = (\n        \"This evening I plan to walk outside in Tokyo. \"\n        \"Please check the latest weather forecast and tell me what I should wear.\"\n    )\n\n    first_events = []\n    async for event in runner.run_async(\n        user_id=session.user_id,\n        session_id=session.id,\n        new_message=types.Content(\n            role=\"user\",\n            parts=[types.Part(text=first_prompt)],\n        ),\n    ):\n        first_events.append(event)\n\n    # Last event from the agent contains the final answer\n    final_event_turn1 = [e for e in first_events if e.author == root_agent.name][-1]\n\n    # Print the whole event structure (safe for any ADK version)\n    print(\"---- Agent response (turn 1) ----\")\n    # pprint.pp(final_event_turn1)\n    pretty_print(final_event_turn1)\n\n    print(\"\\n=== Turn 2: follow-up in the same session (tests memory) ===\")\n    second_prompt = (\n        \"I liked your outfit suggestion. Can you briefly remind me what you recommended \"\n        \"and add one more useful item I should bring with me?\"\n    )\n\n    second_events = []\n    async for event in runner.run_async(\n        user_id=session.user_id,\n        session_id=session.id,\n        new_message=types.Content(\n            role=\"user\",\n            parts=[types.Part(text=second_prompt)],\n        ),\n    ):\n        second_events.append(event)\n\n    final_event_turn2 = [e for e in second_events if e.author == root_agent.name][-1]\n\n    print(\"---- Agent response (turn 2) ----\")\n    # pprint.pp(final_event_turn2)\n    pretty_print(final_event_turn2)\n\n\nawait run_session_example()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T07:10:58.195781Z","iopub.execute_input":"2025-11-24T07:10:58.196524Z","iopub.status.idle":"2025-11-24T07:11:02.462788Z","shell.execute_reply.started":"2025-11-24T07:10:58.196489Z","shell.execute_reply":"2025-11-24T07:11:02.461733Z"}},"outputs":[{"name":"stdout","text":"=== Turn 1: initial question ===\n[plugin] Agent runs so far: 6\n[plugin] LLM request #6 (model=gemini-2.5-flash-lite)\n---- Agent response (turn 1) ----\nThe weather in Tokyo this evening is expected to be partly cloudy with a temperature around 50-55¬∞F (10-13¬∞C). The wind will be light.\n\nFor your walk, I recommend wearing a light jacket or a warm sweater, along with comfortable shoes. You likely won't need an umbrella.\n\n=== Turn 2: follow-up in the same session (tests memory) ===\n[plugin] Agent runs so far: 7\n[plugin] LLM request #7 (model=gemini-2.5-flash-lite)\n---- Agent response (turn 2) ----\nI recommended wearing a light jacket or a warm sweater and comfortable shoes for your walk this evening. The weather is expected to be partly cloudy with temperatures around 50-55¬∞F (10-13¬∞C).\n\nGiven the temperature and the potential for a slight evening chill, it would also be useful to bring a scarf. This will help keep you warm and comfortable during your walk.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}