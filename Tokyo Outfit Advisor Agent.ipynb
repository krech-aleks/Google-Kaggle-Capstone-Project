{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Writeup\n",
    "\n",
    "## Track\n",
    "Concierge Agents\n",
    "\n",
    "## Problem & Solution Pitch\n",
    "### Problem\n",
    "\n",
    "People often waste time checking the weather and still feel unsure about what to wear - especially in a city like Tokyo, where conditions change quickly.\n",
    "\n",
    "### Solution\n",
    "\n",
    "I will build a Tokyo Outfit Advisor Agent that automatically fetches the latest weather forecast and gives simple, clear clothing recommendations based on real-time conditions.\n",
    "\n",
    "## Agent Purpose\n",
    "\n",
    "This agent provides real-time clothing advice for walks in Tokyo based on the latest weather conditions.\n",
    "It uses the Gemini 2.5 Flash-Lite model to interpret user queries, search for current weather information, and generate clear, practical recommendations.\n",
    "\n",
    "## Features Included (Required 3+, I have 4):\n",
    "\n",
    "„Éª LLM-powered agent ‚úîÔ∏è\n",
    "The main reasoning and planning steps are performed by a Gemini-based agent.\n",
    "\n",
    "„Éª Built-in Google Search Tool (Grounded Web Search) ‚úîÔ∏è\n",
    "The agent retrieves live weather information for Tokyo using the integrated search tool.\n",
    "\n",
    "„Éª Session & Memory Support ‚úîÔ∏è\n",
    "Through InMemorySessionService, the agent remembers earlier messages within the same session, enabling natural follow-up interactions.\n",
    "\n",
    "„Éª Observability Plugins (Invocation counter + logging) ‚úîÔ∏è\n",
    "A custom plugin tracks how many times the agent is invoked. Logging is enabled for visibility during execution.\n",
    "\n",
    "## How the Agent Works\n",
    "\n",
    "The user asks how to dress for a walk in Tokyo.\n",
    "The agent performs a grounded web search to obtain the current weather forecast and then generates clear, concise clothing advice.\n",
    "If the user asks follow-up questions (e.g., what else to bring), the agent uses session memory to recall its previous recommendation and answer consistently.\n",
    "\n",
    "## Warning!\n",
    "This file was designed to execute in kaggle workspace as a neccessary part of Google/Kaggle AI Agents Intensive Course.\n",
    "So if you would like to execute it in jupyter lab, you need to change it a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-24T06:56:13.147595Z",
     "iopub.status.busy": "2025-11-24T06:56:13.147173Z",
     "iopub.status.idle": "2025-11-24T06:56:13.589224Z",
     "shell.execute_reply": "2025-11-24T06:56:13.588155Z",
     "shell.execute_reply.started": "2025-11-24T06:56:13.147534Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T06:56:19.652176Z",
     "iopub.status.busy": "2025-11-24T06:56:19.651849Z",
     "iopub.status.idle": "2025-11-24T06:56:19.769696Z",
     "shell.execute_reply": "2025-11-24T06:56:19.768417Z",
     "shell.execute_reply.started": "2025-11-24T06:56:19.652152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    print(\"‚úÖ Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T06:56:22.477780Z",
     "iopub.status.busy": "2025-11-24T06:56:22.477275Z",
     "iopub.status.idle": "2025-11-24T06:56:50.635950Z",
     "shell.execute_reply": "2025-11-24T06:56:50.634747Z",
     "shell.execute_reply.started": "2025-11-24T06:56:22.477752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import google_search\n",
    "from google.genai import types\n",
    "from google.adk.plugins.base_plugin import BasePlugin\n",
    "\n",
    "print(\"‚úÖ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T06:57:03.965013Z",
     "iopub.status.busy": "2025-11-24T06:57:03.964378Z",
     "iopub.status.idle": "2025-11-24T06:57:04.163916Z",
     "shell.execute_reply": "2025-11-24T06:57:04.162446Z",
     "shell.execute_reply.started": "2025-11-24T06:57:03.964978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# You don't need this block if execute outside kaggle workspace.\n",
    "from IPython.core.display import display, HTML\n",
    "from jupyter_server.serverapp import list_running_servers\n",
    "\n",
    "# Gets the proxied URL in the Kaggle Notebooks environment\n",
    "def get_adk_proxy_url():\n",
    "    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n",
    "    ADK_PORT = \"8000\"\n",
    "\n",
    "    servers = list(list_running_servers())\n",
    "    if not servers:\n",
    "        raise Exception(\"No running Jupyter servers found.\")\n",
    "\n",
    "    baseURL = servers[0]['base_url']\n",
    "\n",
    "    try:\n",
    "        path_parts = baseURL.split('/')\n",
    "        kernel = path_parts[2]\n",
    "        token = path_parts[3]\n",
    "    except IndexError:\n",
    "        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n",
    "\n",
    "    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n",
    "    url = f\"{PROXY_HOST}{url_prefix}\"\n",
    "\n",
    "    styled_html = f\"\"\"\n",
    "    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n",
    "        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n",
    "            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n",
    "        </div>\n",
    "        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n",
    "            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n",
    "            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n",
    "                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n",
    "                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n",
    "                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n",
    "            </ol>\n",
    "            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n",
    "        </div>\n",
    "        <a href='{url}' target='_blank' style=\"\n",
    "            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n",
    "            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n",
    "            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n",
    "            Open ADK Web UI (after running cell below) ‚Üó\n",
    "        </a>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    display(HTML(styled_html))\n",
    "\n",
    "    return url_prefix\n",
    "\n",
    "print(\"‚úÖ Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T06:59:30.594896Z",
     "iopub.status.busy": "2025-11-24T06:59:30.594465Z",
     "iopub.status.idle": "2025-11-24T06:59:30.602773Z",
     "shell.execute_reply": "2025-11-24T06:59:30.601189Z",
     "shell.execute_reply.started": "2025-11-24T06:59:30.594858Z"
    }
   },
   "outputs": [],
   "source": [
    "# Observability plugin\n",
    "class CountInvocationPlugin(BasePlugin):\n",
    "    \"\"\"Simple observability plugin that logs agent, LLM, and tool calls.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(name=\"count_invocation\")\n",
    "        self.agent_count = 0\n",
    "        self.tool_count = 0\n",
    "        self.llm_request_count = 0\n",
    "\n",
    "    async def before_agent_callback(self, agent, callback_context):\n",
    "        \"\"\"Called before each agent run.\"\"\"\n",
    "        self.agent_count += 1\n",
    "        print(f\"[plugin] Agent runs so far: {self.agent_count}\")\n",
    "\n",
    "    async def before_model_callback(self, callback_context, llm_request, **kwargs):\n",
    "        \"\"\"Called before each LLM request.\"\"\"\n",
    "        self.llm_request_count += 1\n",
    "        # llm_request is a LlmRequest object; model name is in llm_request.model\n",
    "        print(f\"[plugin] LLM request #{self.llm_request_count} (model={llm_request.model})\")\n",
    "\n",
    "    async def after_tool_callback(self, tool, tool_context, result):\n",
    "        \"\"\"Called after each tool invocation.\"\"\"\n",
    "        self.tool_count += 1\n",
    "        print(f\"[plugin] Tool '{tool.name}' completed. Total tool calls: {self.tool_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:02:37.079608Z",
     "iopub.status.busy": "2025-11-24T07:02:37.079243Z",
     "iopub.status.idle": "2025-11-24T07:02:37.086165Z",
     "shell.execute_reply": "2025-11-24T07:02:37.085145Z",
     "shell.execute_reply.started": "2025-11-24T07:02:37.079581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Root Agent defined.\n"
     ]
    }
   ],
   "source": [
    "root_agent = Agent(\n",
    "    name=\"tokyo_outfit_agent\",\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    description=\"Agent that checks Tokyo weather and suggests what to wear.\",\n",
    "    instruction=(\n",
    "        \"You are a helpful assistant based in Tokyo.\\n\"\n",
    "        \"Your task is to:\\n\"\n",
    "        \"1) Use the google_search tool to check the latest weather forecast for Tokyo.\\n\"\n",
    "        \"2) Based on the forecast, recommend what the user should wear (layers, jacket, \"\n",
    "        \"umbrella, shoes, etc.).\\n\"\n",
    "        \"3) Always answer in clear English.\\n\"\n",
    "        \"4) Never hallucinate weather data; if search fails, say so explicitly.\"\n",
    "    ),\n",
    "    tools=[google_search],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Root Agent defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:02:39.440779Z",
     "iopub.status.busy": "2025-11-24T07:02:39.440319Z",
     "iopub.status.idle": "2025-11-24T07:02:39.447879Z",
     "shell.execute_reply": "2025-11-24T07:02:39.446875Z",
     "shell.execute_reply.started": "2025-11-24T07:02:39.440744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Runner created.\n"
     ]
    }
   ],
   "source": [
    "# Runner with plugin for observability\n",
    "runner = InMemoryRunner(\n",
    "    agent=root_agent,\n",
    "    app_name=\"tokyo_weather_outfit_app\",\n",
    "    plugins=[CountInvocationPlugin()],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Runner created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:10:01.311176Z",
     "iopub.status.busy": "2025-11-24T07:10:01.310799Z",
     "iopub.status.idle": "2025-11-24T07:10:01.318746Z",
     "shell.execute_reply": "2025-11-24T07:10:01.317205Z",
     "shell.execute_reply.started": "2025-11-24T07:10:01.311145Z"
    }
   },
   "outputs": [],
   "source": [
    "def pretty_print(event):\n",
    "    \"\"\"Safely extract and print only the human-readable text from an Event.\"\"\"\n",
    "    try:\n",
    "        content = getattr(event, \"content\", None)\n",
    "        if not content:\n",
    "            print(event)\n",
    "            return\n",
    "\n",
    "        parts = getattr(content, \"parts\", [])\n",
    "        texts = []\n",
    "        for part in parts:\n",
    "            text = getattr(part, \"text\", None)\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "\n",
    "        if texts:\n",
    "            print(\"\\n\".join(texts))\n",
    "        else:\n",
    "            print(\"(no text content)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while printing event: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:10:58.196524Z",
     "iopub.status.busy": "2025-11-24T07:10:58.195781Z",
     "iopub.status.idle": "2025-11-24T07:11:02.462788Z",
     "shell.execute_reply": "2025-11-24T07:11:02.461733Z",
     "shell.execute_reply.started": "2025-11-24T07:10:58.196489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Turn 1: initial question ===\n",
      "[plugin] Agent runs so far: 6\n",
      "[plugin] LLM request #6 (model=gemini-2.5-flash-lite)\n",
      "---- Agent response (turn 1) ----\n",
      "The weather in Tokyo this evening is expected to be partly cloudy with a temperature around 50-55¬∞F (10-13¬∞C). The wind will be light.\n",
      "\n",
      "For your walk, I recommend wearing a light jacket or a warm sweater, along with comfortable shoes. You likely won't need an umbrella.\n",
      "\n",
      "=== Turn 2: follow-up in the same session (tests memory) ===\n",
      "[plugin] Agent runs so far: 7\n",
      "[plugin] LLM request #7 (model=gemini-2.5-flash-lite)\n",
      "---- Agent response (turn 2) ----\n",
      "I recommended wearing a light jacket or a warm sweater and comfortable shoes for your walk this evening. The weather is expected to be partly cloudy with temperatures around 50-55¬∞F (10-13¬∞C).\n",
      "\n",
      "Given the temperature and the potential for a slight evening chill, it would also be useful to bring a scarf. This will help keep you warm and comfortable during your walk.\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "async def run_session_example() -> None:\n",
    "    # Create a session so that the agent can keep context between turns\n",
    "    session = await runner.session_service.create_session(\n",
    "        app_name=runner.app_name,\n",
    "        user_id=\"demo_user\",\n",
    "    )\n",
    "\n",
    "    print(\"=== Turn 1: initial question ===\")\n",
    "    first_prompt = (\n",
    "        \"This evening I plan to walk outside in Tokyo. \"\n",
    "        \"Please check the latest weather forecast and tell me what I should wear.\"\n",
    "    )\n",
    "\n",
    "    first_events = []\n",
    "    async for event in runner.run_async(\n",
    "        user_id=session.user_id,\n",
    "        session_id=session.id,\n",
    "        new_message=types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part(text=first_prompt)],\n",
    "        ),\n",
    "    ):\n",
    "        first_events.append(event)\n",
    "\n",
    "    # Last event from the agent contains the final answer\n",
    "    final_event_turn1 = [e for e in first_events if e.author == root_agent.name][-1]\n",
    "\n",
    "    # Print the whole event structure (safe for any ADK version)\n",
    "    print(\"---- Agent response (turn 1) ----\")\n",
    "    # pprint.pp(final_event_turn1)\n",
    "    pretty_print(final_event_turn1)\n",
    "\n",
    "    print(\"\\n=== Turn 2: follow-up in the same session (tests memory) ===\")\n",
    "    second_prompt = (\n",
    "        \"I liked your outfit suggestion. Can you briefly remind me what you recommended \"\n",
    "        \"and add one more useful item I should bring with me?\"\n",
    "    )\n",
    "\n",
    "    second_events = []\n",
    "    async for event in runner.run_async(\n",
    "        user_id=session.user_id,\n",
    "        session_id=session.id,\n",
    "        new_message=types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part(text=second_prompt)],\n",
    "        ),\n",
    "    ):\n",
    "        second_events.append(event)\n",
    "\n",
    "    final_event_turn2 = [e for e in second_events if e.author == root_agent.name][-1]\n",
    "\n",
    "    print(\"---- Agent response (turn 2) ----\")\n",
    "    # pprint.pp(final_event_turn2)\n",
    "    pretty_print(final_event_turn2)\n",
    "\n",
    "\n",
    "await run_session_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
